{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c252b1d-bfef-41d3-931e-b91445a2800c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display \n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Load the dataset  \n",
    "website_traffic = pd.read_csv(\"website_traffic.csv\")\n",
    "website_traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72858ddb-0c2b-4bf6-bf87-ad35440d706b",
   "metadata": {},
   "outputs": [],
   "source": [
    "website_traffic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c009f2b4-a8e9-4573-9f59-fb966740efd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 6  # Determine how many of the largest correlations to consider (top 6)  \n",
    "\n",
    "# Calculate the correlation matrix while restricting to numeric columns  \n",
    "correlation_matrix = website_traffic.corr(numeric_only=True)  # Restricts the correlation calculation to only numeric columns in the DataFrame.  \n",
    "\n",
    "# Display the correlation matrix  \n",
    "display(correlation_matrix) \n",
    "\n",
    "# Retrieve the top k columns with the highest correlation to \"Conversion Rate\"  \n",
    "cols = correlation_matrix.nlargest(k, \"Conversion Rate\")['Conversion Rate'].index  \n",
    "\n",
    "# Print the indices of the top correlated columns  \n",
    "print(\"\\nTop correlated columns with 'Conversion Rate':\")  \n",
    "cols  # Prints out the indices (column names) of the highest correlated columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936cf037-407a-4780-ac47-6fac680f7bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation coefficients for the selected columns  \n",
    "cm = np.corrcoef(website_traffic[cols].values.T)\n",
    "\n",
    "# Create and display the heatmap  \n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "sns.heatmap(cm, vmax=1.0, linewidth=0.01, square=True, annot = True, fmt=\".2f\",cmap='coolwarm', xticklabels=cols.values, annot_kws = {'size': 12}, yticklabels=cols.values)\n",
    "plt.title('Correlation Heatmap (Sorted by Impact on Conversion Rate)', fontsize=16)  \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22f4866-7b24-4bfa-9c18-931f3d734a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 2\n",
    "\n",
    "# Feature Selection: Choose features with a positive correlation as potential predictors for Conversion Rate.  \n",
    "positive_corr_features = correlation_matrix['Conversion Rate'][correlation_matrix['Conversion Rate'] > 0].index  \n",
    "\n",
    "# Print the positive correlated features with Conversion Rate  \n",
    "print(\"\\nFeatures with a positive correlation to 'Conversion Rate':\")  \n",
    "print(positive_corr_features)\n",
    "\n",
    "# Create a DataFrame to show all the positive correlated features and their data  \n",
    "positive_corr_data = website_traffic[positive_corr_features]  \n",
    "\n",
    "# Display the DataFrame with positive correlated features  \n",
    "# print(\"\\nData for features with a positive correlation to 'Conversion Rate':\")  \n",
    "# display(positive_corr_data)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc39a8a1-9797-4901-8e2f-8cc0975040da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 3: Define X and y for prediction  \n",
    "# drop to ensure that the feature matrix X only contains the input features and not the target variable, making it suitable for training predictive models.\n",
    "x = website_traffic[positive_corr_features].drop(['Conversion Rate'], axis=1)  \n",
    "y = website_traffic['Conversion Rate']  \n",
    "\n",
    "print(\"\\nFeature matrix (X):\")  \n",
    "display(x)  \n",
    "\n",
    "print(\"\\nTarget variable (y):\")  \n",
    "display(y)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ede527-5411-4fe3-ab36-7183f42b929c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 4: Data Splitting  \n",
    "train_x, val_x, train_y, val_y = train_test_split(x, y, test_size=0.2, random_state= 40)  \n",
    "\n",
    "print(\"\\nTraining feature matrix (train_x):\")  \n",
    "display(train_x)  \n",
    "\n",
    "print(\"\\nValidation feature matrix (val_x):\")  \n",
    "display(val_x)  \n",
    "\n",
    "print(\"\\nTraining target variable (train_y):\")  \n",
    "display(train_y)  \n",
    "\n",
    "print(\"\\nValidation target variable (val_y):\")  \n",
    "display(val_y)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cec1313-9cfc-4485-b246-fd755eea1e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 5: Calculate MAE using Decision Tree Regressor  \n",
    "# Create a Decision Tree Regressor model  \n",
    "model = LinearRegression()\n",
    "# model = DecisionTreeRegressor(random_state= 42)\n",
    "model.fit(train_x, train_y)  # Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5dfd05-9740-48ee-9739-0d7ebc09ad32",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 6: Analyse Results\n",
    "val_y_pred = model.predict(val_x) \n",
    "# Evaluate the model using Mean Absolute Error (MAE)  \n",
    "mae = mean_absolute_error(val_y, val_y_pred)  \n",
    "\n",
    "print(\"\\nModel Evaluation:\")  \n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")  \n",
    "\n",
    "# Interpretation of the MAE  \n",
    "interpretation = (  \n",
    "    \"The Mean Absolute Error (MAE) of approximately {:.4f} indicates that, on average, the predictions made \"  \n",
    "    \"by the Linear Regression model for the Conversion Rate are off by about {:.4f} units. Since the Conversion \"  \n",
    "    \"Rate typically ranges between 0 and 1, this MAE value suggests that the model's predictions are quite accurate\" \n",
    "    \"(no vast differences between the trainning and testing), \"  \n",
    "    \"with errors being relatively small compared to the range of possible values. This indicates that the Linear \"  \n",
    "    \"Regression model is effectively capturing the underlying trends in the data, leading to a good performance in \"  \n",
    "    \"predicting the target variable. Overall, the model demonstrates a strong ability to predict conversion rates with \"  \n",
    "    \"minimal average error.\"  \n",
    ").format(mae, mae)  \n",
    "\n",
    "print(\"\\nInterpretation of MAE:\")  \n",
    "print(interpretation)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28201dd8-5e57-41f4-845e-c502c41792ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 7-9: Determine the Optimal Number of Clusters  \n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "\n",
    "# Standardize features  \n",
    "# scaler = StandardScaler()  \n",
    "# x_scaled = scaler.fit_transform(x)  # Use the previously defined `x` for features  \n",
    "\n",
    "# Initialize a list to store inertia values  \n",
    "inertia_values = []  \n",
    "\n",
    "# Use a for loop to calculate inertia for cluster counts from 1 to 10  \n",
    "for i in range(1, 11):  \n",
    "    kmeans = KMeans(n_clusters=i, random_state=42)  \n",
    "    kmeans.fit_predict(x)  # Fit on the x\n",
    "    inertia_values.append(kmeans.inertia_)  # Collect the inertia value for each k  \n",
    "\n",
    "# Plot the inertia values to visualize the elbow method  \n",
    "plt.figure(figsize=(10, 6))  \n",
    "plt.plot(range(1, 11), inertia_values, marker='o')  \n",
    "plt.xlabel('Number of Clusters', fontsize=14)  \n",
    "plt.ylabel('Inertia (WCSS)', fontsize=14)  \n",
    "plt.title('Elbow Method for Determining Optimal Number of Clusters', fontsize=16)  \n",
    "plt.xticks(range(1, 11))  # Set x-tick marks  \n",
    "plt.grid(True)  \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bdb7b8-1067-44e0-93bb-5b7cf8a80d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit KMeans with optimal clusters  \n",
    "optimal_k = 5\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42)  \n",
    "clusters = kmeans.fit_predict(x)   \n",
    "\n",
    "# Create a new DataFrame to hold the features and cluster labels  \n",
    "clustered_data = pd.DataFrame(x, columns=x.columns)  # Use the column names from `x`  \n",
    "clustered_data['Cluster'] = clusters  # Add the cluster labels  \n",
    "\n",
    "# Print the new DataFrame with cluster labels   \n",
    "print(\"\\nDataset with Cluster Labels:\")  \n",
    "display(clustered_data)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ad78cf-29b9-4895-ad0e-eae791aeaa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 9 Cluster Analysis\n",
    "cluster_means = clustered_data.groupby('Cluster').mean()  \n",
    "print(\"\\nMean values for each cluster:\")  \n",
    "cluster_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75848f00-39d4-49d9-b4f9-f1eac34dea4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 10  \n",
    "# Additional features to include  \n",
    "additional_features = ['Bounce Rate', 'Conversion Rate']  \n",
    "# Add the additional features to the clustered_data DataFrame  \n",
    "for feature in additional_features:  \n",
    "    if feature in website_traffic.columns:  # Ensure it exists in the original DataFrame  \n",
    "        clustered_data[feature] = website_traffic[feature]  \n",
    "    else:  \n",
    "        print(f\"{feature} does not exist in the original dataset.\")  \n",
    "\n",
    "# Recalculate mean values including additional features  \n",
    "cluster_means = clustered_data.groupby('Cluster').mean()  \n",
    "print(\"\\nUpdated mean values for each cluster with additional features:\")  \n",
    "display(cluster_means)  \n",
    "\n",
    "# Plot the mean values for each feature (including additional features) across clusters  \n",
    "features = cluster_means.columns  \n",
    "num_features = len(features)  \n",
    "\n",
    "# Set the figure size and layout  \n",
    "plt.figure(figsize=(num_features * 3, 7))  # Adjust width and height  \n",
    "\n",
    "# Plot each feature's mean across clusters  \n",
    "for i, feature in enumerate(features):  \n",
    "    plt.subplot(1, num_features, i + 1)  # 1 row, num_features columns  \n",
    "    plt.plot(cluster_means.index, cluster_means[feature], marker='o')  \n",
    "    plt.title(feature)  \n",
    "    plt.xlabel('Cluster')  \n",
    "    plt.ylabel('Mean Value')  \n",
    "\n",
    "plt.tight_layout()  \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866ec7de-e3cb-4e4b-81e8-8fdc2c87488b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 11\n",
    "\n",
    "# The analysis of the clusters reveals distinct patterns in user engagement and website performance.   \n",
    "# Cluster 4 stands out as the best-performing group, characterized by high session duration, significant time spent on individual pages, a low bounce rate, and the highest conversion rate.   \n",
    "# This suggests that users are highly engaged with the websites in this cluster, leading to effective conversions.   \n",
    "\n",
    "# Conversely, Cluster 3 emerges as the worst-performing group, exhibiting the lowest page views, session duration, and conversion rate, i\n",
    "#indicating users spend minimal time on these sites and are less likely to engage deeply with the content.   \n",
    "\n",
    "# In contrast, Cluster 2 demonstrates strong user retention, reflected in high previous visits, while still maintaining significant page views.   \n",
    "# This indicates strong user loyalty and retention, suggesting that users find value in returning to these websites.  \n",
    "\n",
    "# Clusters 0 and 1 exhibit average performance, with Cluster 0 showing a concerningly high bounce rate, indicating potential issues with user engagement or content relevancy.   \n",
    "# Notably, despite its high bounce rate, Cluster 0 maintains a very high conversion rate and a relatively high time on page.   \n",
    "# This suggests that while many users leave quickly, those who stay are highly engaged and likely to convert.  \n",
    "\n",
    "# Cluster 1 shows a balanced performance across most metrics, indicating stable but not outstanding user engagement.   \n",
    "# This cluster could benefit from targeted improvements to boost specific metrics like conversion rate or session duration.  \n",
    "\n",
    "# Overall, the findings highlight that Cluster 4 represents high traffic and effective user engagement,   \n",
    "# while Cluster 3 signals low traffic and poor engagement. The sharp drop in conversion rate for Cluster 3,   \n",
    "# combined with low session duration and page views, suggests that these websites may have significant issues with user experience or content relevance,   \n",
    "# guiding potential strategies for improvement across different website performance metrics.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
